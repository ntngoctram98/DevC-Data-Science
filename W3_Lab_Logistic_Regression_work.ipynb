{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "W3_Lab_Logistic_Regression-work.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Y8VMWjQtJOS7",
        "mc9xgpmqJOXP"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntngoctram98/DevC-Data-Science/blob/master/W3_Lab_Logistic_Regression_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci0ljwt1JORA",
        "colab_type": "text"
      },
      "source": [
        "# Week 3 - Lab - Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyARLQRxJORF",
        "colab_type": "text"
      },
      "source": [
        "## Recap\n",
        "![Imgur](https://i.imgur.com/UB4Kg0w.jpg)\n",
        "[Link to sketchboard](https://sketchboard.me/tBjCwrhXsFwu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqZBXnyiJORI",
        "colab_type": "text"
      },
      "source": [
        "## Basic NLP Flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVaPWQE3JORK",
        "colab_type": "text"
      },
      "source": [
        "- **Step 1**: Clean data\n",
        "    - Remove all irrelevant characters such as any non alphanumeric characters\n",
        "    - Tokenize your text by separating it into individual words \n",
        "    - Remove words that are not relevant, such as “@” twitter mentions or urls \n",
        "    - Convert all characters to **lowercase**, in order to treat words such as “hello”, “Hello”, and “HELLO” the same \n",
        "    - Consider **lemmatization** (reduce words such as “am”, “are”, and “is” to a common form such as “be”)\n",
        "- **Step 2**: Representation\n",
        "    - Bag of Words or TFIDF\n",
        "- **Step 3**: Classification\n",
        "    - Naive Bayes\n",
        "    - Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NagtOi7nJORM",
        "colab_type": "text"
      },
      "source": [
        "## String manipulation in Python\n",
        "**Before going to NLP we need tools to handle string**\n",
        "\n",
        "One place where the Python language really shines is in the manipulation of strings. This section will cover some of Python's built-in string methods and formatting operations, before moving on to a quick guide to the extremely useful subject of regular expressions. Such string manipulation patterns come up often in the context of data science work\n",
        "\n",
        "### Formatting strings: Adjusting case\n",
        "\n",
        "Python makes it quite easy to adjust the case of a string. Here we'll look at the `upper()`, `lower()`, `capitalize()`, and `swapcase()` methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tee5NMCJORO",
        "colab_type": "code",
        "outputId": "d0b093cf-1eab-4158-a57f-f2bdab4a6515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fox = 'tHe qUICk bROWn fOx.'\n",
        "# Apply the functions above to `fox` and print out the results\n",
        "# Your code here\n",
        "\n",
        "print(fox.lower(),fox.upper(),fox.capitalize(),fox.swapcase())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the quick brown fox. THE QUICK BROWN FOX. The quick brown fox. ThE QuicK BrowN FoX.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpAOOPL8JORY",
        "colab_type": "text"
      },
      "source": [
        "### Adding and removing spaces\n",
        "\n",
        "Another common need is to remove spaces (or other characters) from the beginning or end of the string. The basic method of removing characters is the `strip()` method, which strips whitespace from the beginning and end of the line. To remove just space to the right or left, use `rstrip()` or `lstrip()` respectively.\n",
        "\n",
        "To remove characters other than spaces, you can pass the desired character to the `strip()` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0sO6IPqJORa",
        "colab_type": "code",
        "outputId": "9e7dda72-7abd-45c9-a58c-ffeaef9059fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "line = '         this is the content         '\n",
        "\n",
        "# Apply strip(), rstrip(), lstrip() to 'line' and print the results out\n",
        "# Your code here\n",
        "print(line.strip())\n",
        "\n",
        "num = '00000000435'\n",
        "# Remove all of the zeros from num\n",
        "# Your code here\n",
        "\n",
        "print(str(int(num)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is the content\n",
            "435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwhskblsJORl",
        "colab_type": "text"
      },
      "source": [
        "### Finding and replacing and splitting\n",
        "\n",
        "If you want to find occurrences of a certain character in a string, the `find()`, `index()` and `replace()` methods are the best built-in methods.\n",
        "\n",
        "`find()` and `index()` are very similar, in that they search for the first occurrence of a character or substring within a string, and return the index of the substring.\n",
        "\n",
        "The `split()` method is perhaps more useful; it finds all instances of the split-point and returns the substrings in between. The default is to split on any whitespace, returning a list of the individual words in a string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpL0qLE7JORo",
        "colab_type": "code",
        "outputId": "5776ae11-c598-4ace-91c1-87c20eee09b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "line = 'the quick brown fox jumped over a lazy dog'\n",
        "\n",
        "# Find the index of 'fox' in 'line' using find() and index()\n",
        "# Your code here\n",
        "\n",
        "print(line.find('fox'))\n",
        "\n",
        "# Let's replace 'brown' with 'red'\n",
        "# Your code here\n",
        "\n",
        "print(line.replace('brown','red'))\n",
        "\n",
        "# List all words in 'line' and put them in an array\n",
        "# Your 1 line of code here\n",
        "\n",
        "print(line.split())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "the quick red fox jumped over a lazy dog\n",
            "['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'a', 'lazy', 'dog']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb0lz2CZJORv",
        "colab_type": "text"
      },
      "source": [
        "Note that if you would like to undo a `split()`, you can use the `join()` method, which returns a string built from a splitpoint and an iterable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtavkIyLJORy",
        "colab_type": "code",
        "outputId": "a956382e-a1fa-4468-a422-1ad7282154aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'--'.join(['1', '2', '3'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1--2--3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLtQJ3LaJOR_",
        "colab_type": "text"
      },
      "source": [
        "A common pattern is to use the special character \"\\n\" (newline) to join together lines:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poR5v9xsJOSC",
        "colab_type": "code",
        "outputId": "ec50d949-71e5-44f4-fb6e-180173af50c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"\\n\".join(['Rules in family:', '1. Your wife is always right.', '2. If she is wrong, check the first rule again.']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rules in family:\n",
            "1. Your wife is always right.\n",
            "2. If she is wrong, check the first rule again.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucNTELR-JOSK",
        "colab_type": "text"
      },
      "source": [
        "### Regular Expression\n",
        "\n",
        "In Python, regular expressions are supported by the `re` module.\n",
        "\n",
        "A regular expression (or RE) specifies a set of strings that matches it; the functions in this module let you check if a particular string matches a given regular expression (or if a given regular expression matches a particular string, which comes down to the same thing).\n",
        "\n",
        "Let's walk through some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYTdk_CZJOSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57RhsYO0JOSU",
        "colab_type": "code",
        "outputId": "04845bc3-4ac5-460b-c12d-3fce5bcba59d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "email_regex = '\\w+@\\w+\\.[a-z]{2}'\n",
        "text = \"To email Hai Minh, try minhdh@coderschool.vn or the older address haiminh101@yahoo.vn\"\n",
        "re.findall(email_regex, text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['minhdh@coderschool.vn', 'haiminh101@yahoo.vn']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1sM42oLJOSc",
        "colab_type": "code",
        "outputId": "b37d7081-a66a-4bf1-c112-59c7b65f7955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Replacing these email addresses with another string, perhaps to hide addresses in the output:\n",
        "re.sub(email_regex, '--@--.--', text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To email Hai Minh, try --@--.-- or the older address --@--.--'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acTMkh_wJOSk",
        "colab_type": "code",
        "outputId": "0e128bb1-5432-4a9a-ed4f-819ac2badf0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The following will match any lower-case vowel:\n",
        "re.split('[aeiou]', 'consequential')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['c', 'ns', 'q', '', 'nt', '', 'l']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kogw3csqJOSs",
        "colab_type": "text"
      },
      "source": [
        "You may need to extract from a document specific numerical codes that consist of a capital letter followed by a digit. You could do this as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1GkbqUXJOSv",
        "colab_type": "code",
        "outputId": "8e39caf8-42af-4aab-e135-2705170c9be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "re.findall('[A-Z][0-9]+', '1043879, G2, H6')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['G2', 'H6']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aseEdAcFJOS4",
        "colab_type": "text"
      },
      "source": [
        "The following table lists a few of these characters that are commonly useful:\n",
        "\n",
        "| Character | Description | Character | Description |\n",
        "|------------|-----------|------------|-----------|\n",
        "| \"\\d\" | Match any digit   | \"\\D\" | Match any non-digit|\n",
        "| \"\\s\" | Match any whitespace   | \"\\S\" | Match any non-whitespace|\n",
        "| \"\\w\" | Match any alphanumeric char  | \"\\W\" | Match any non-alphanumeric char|\n",
        "\n",
        "| Character | Description | Example |\n",
        "|------------|-----------|------------|\n",
        "| ? | Match zero or one repetitions of preceding |  \"ab?\" matches \"a\" or \"ab\" |\n",
        "| * | Match zero or more repetitions of preceding | \"ab*\" matches \"a\", \"ab\", \"abb\", \"abbb\"... |\n",
        "| + | Match one or more repetitions of preceding |  \"ab+\" matches \"ab\", \"abb\", \"abbb\"... but not \"a\" |\n",
        "| {n} | Match n repetitions of preceding | \"ab{2}\" matches \"abb\" |\n",
        "| {m,n} | Match between m and n repetitions of preceding |  \"ab{2,3}\" matches \"abb\" or \"abbb\" |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8VMWjQtJOS7",
        "colab_type": "text"
      },
      "source": [
        "### Further Resources on Regular Expressions\n",
        "\n",
        "* [Python's re package Documentation](https://docs.python.org/3/library/re.html)\n",
        "* [Python's official regular expression HOWTO](https://docs.python.org/3/howto/regex.html)\n",
        "* [Mastering Regular Expressions (OReilly, 2006)](http://shop.oreilly.com/product/9780596528126.do)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0cCgr_QJOS9",
        "colab_type": "text"
      },
      "source": [
        "## 1. Sentiment analysis\n",
        "This contest is taken from the real task of Text Processing.\n",
        "\n",
        "The task is to build a model that will determine the tone (positive, negative) of the text. To do this, you will need to train the model on the existing data (train.csv). The resulting model will have to determine the class (neutral, positive, negative) of new texts. The dataset contains the following fields:\n",
        "\n",
        "| Field name | Meaning |\n",
        "|------------|-----------|\n",
        "| ItemID  | id of twit|\n",
        "| Sentiment | sentiment (1-positive, 0-negative)|\n",
        "| SentimentText | text of the twit|\n",
        "\n",
        "Let's first of all have a look at the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtXUT5OeJOTB",
        "colab_type": "code",
        "outputId": "852ea959-e8a0-4a63-9ebd-4a96c2475ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "# Import pandas, numpy and the dataset, save it in a object called 'sentiment'\n",
        "# Your code here\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Read file with param './data/train.csv', encoding='latin-1'\n",
        "\n",
        "path = '/content/train.csv'\n",
        "sentiment = pd.read_csv(path, encoding = 'latin-1')\n",
        "\n",
        "# Let's check sentiment.head(10) and sample(10)\n",
        "# Your code here\n",
        "sentiment.sample(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ItemID</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18345</th>\n",
              "      <td>18357</td>\n",
              "      <td>0</td>\n",
              "      <td>@_ericatsk awwwwwwhhh!! i don't want them too</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66512</th>\n",
              "      <td>66524</td>\n",
              "      <td>0</td>\n",
              "      <td>@blu_angelfire I would have but MM's got it!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>2546</td>\n",
              "      <td>0</td>\n",
              "      <td>i can't type! my mad typing skills are screwe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17462</th>\n",
              "      <td>17474</td>\n",
              "      <td>0</td>\n",
              "      <td>...I wish they provided breakfast in my class.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10586</th>\n",
              "      <td>10598</td>\n",
              "      <td>0</td>\n",
              "      <td>#inever been out on a boat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28440</th>\n",
              "      <td>28452</td>\n",
              "      <td>1</td>\n",
              "      <td>@abednego_jones I'm STILL laughing at ur fooli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15768</th>\n",
              "      <td>15780</td>\n",
              "      <td>0</td>\n",
              "      <td>: Shit! now what, twitters got a mind of its own</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35163</th>\n",
              "      <td>35175</td>\n",
              "      <td>1</td>\n",
              "      <td>@alwinter Yes. Honestly, get one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92101</th>\n",
              "      <td>92113</td>\n",
              "      <td>1</td>\n",
              "      <td>@ColleenLindsay What a great post!!  Thanks fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15201</th>\n",
              "      <td>15213</td>\n",
              "      <td>1</td>\n",
              "      <td>.@nanere Sheila I heart you!! That &amp;quot;Holly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85696</th>\n",
              "      <td>85708</td>\n",
              "      <td>1</td>\n",
              "      <td>@chrishasboobs follow me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54160</th>\n",
              "      <td>54172</td>\n",
              "      <td>0</td>\n",
              "      <td>@autismfamily  Yeah, research that, I don't kn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1647</th>\n",
              "      <td>1648</td>\n",
              "      <td>0</td>\n",
              "      <td>cramps. FUCK YOU. ugh asdfghjkl; in so much p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71233</th>\n",
              "      <td>71245</td>\n",
              "      <td>0</td>\n",
              "      <td>@andycolourbase Just well wasn't in the mood f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48485</th>\n",
              "      <td>48497</td>\n",
              "      <td>1</td>\n",
              "      <td>@Alyssa_Milano good evening!  it's Sunday nigh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57031</th>\n",
              "      <td>57043</td>\n",
              "      <td>1</td>\n",
              "      <td>@basantam If you ask so nicely....OK   Any pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60218</th>\n",
              "      <td>60230</td>\n",
              "      <td>1</td>\n",
              "      <td>@BenAS annoying but will put up with them unti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79726</th>\n",
              "      <td>79738</td>\n",
              "      <td>1</td>\n",
              "      <td>@Arrieb Panting flowers...  putting down some ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39757</th>\n",
              "      <td>39769</td>\n",
              "      <td>1</td>\n",
              "      <td>@AnderLucia made great time...drove the whole ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20178</th>\n",
              "      <td>20190</td>\n",
              "      <td>1</td>\n",
              "      <td>@_WildRose_    what big words. I'm thinking a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ItemID  Sentiment                                      SentimentText\n",
              "18345   18357          0     @_ericatsk awwwwwwhhh!! i don't want them too \n",
              "66512   66524          0      @blu_angelfire I would have but MM's got it! \n",
              "2545     2546          0   i can't type! my mad typing skills are screwe...\n",
              "17462   17474          0    ...I wish they provided breakfast in my class. \n",
              "10586   10598          0                        #inever been out on a boat \n",
              "28440   28452          1  @abednego_jones I'm STILL laughing at ur fooli...\n",
              "15768   15780          0  : Shit! now what, twitters got a mind of its own \n",
              "35163   35175          1                  @alwinter Yes. Honestly, get one \n",
              "92101   92113          1  @ColleenLindsay What a great post!!  Thanks fo...\n",
              "15201   15213          1  .@nanere Sheila I heart you!! That &quot;Holly...\n",
              "85696   85708          1                          @chrishasboobs follow me \n",
              "54160   54172          0  @autismfamily  Yeah, research that, I don't kn...\n",
              "1647     1648          0   cramps. FUCK YOU. ugh asdfghjkl; in so much p...\n",
              "71233   71245          0  @andycolourbase Just well wasn't in the mood f...\n",
              "48485   48497          1  @Alyssa_Milano good evening!  it's Sunday nigh...\n",
              "57031   57043          1  @basantam If you ask so nicely....OK   Any pre...\n",
              "60218   60230          1  @BenAS annoying but will put up with them unti...\n",
              "79726   79738          1  @Arrieb Panting flowers...  putting down some ...\n",
              "39757   39769          1  @AnderLucia made great time...drove the whole ...\n",
              "20178   20190          1  @_WildRose_    what big words. I'm thinking a ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "535MhvoaJOTL",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the structure of a twit varies a lot between twit and twit. They have different lengths, letters, numbers, extrange characters, etc. \n",
        "\n",
        "It is also important to note that **a lot** of words are not correctly spelled, for example the word _\"Juuuuuuuuuuuuuuuuussssst\"_ or the word _\"sooo\"_\n",
        "\n",
        "This makes it hard to mesure how positive or negative are the words within the twits.\n",
        "\n",
        "So we need a way of scoring the words such that words that appear in positive twits have greater score that those that appear in negative twits.\n",
        "\n",
        "But first... how do we represent the twits as vectors we can input to our algorithm?\n",
        "\n",
        "### Bag of words\n",
        "\n",
        "One thing we could do to represent the twits as equal-sized vectors of numbers is the following:\n",
        "\n",
        "* Create a list (vocabulary) with all the unique words in the whole corpus of twits. \n",
        "* We construct a feature vector from each twit that contains the counts of how often each word occurs in the particular twit\n",
        "\n",
        "_Note that since the unique words in each twit represent only a small subset of all the words in the bag-of-words vocabulary, the feature vectors will mostly consist of zeros_\n",
        "\n",
        "Lets construct the bag of words. We will work with a smaller example for illustrative purposes, and at the end we will work with our real data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw5UzVRVJOTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twits = [\n",
        "    'This is amazing!',\n",
        "    'ML is the best, yes it is',\n",
        "    'I am not sure about how this is going to end...'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZXN5fetJOTY",
        "colab_type": "text"
      },
      "source": [
        "Let's import [CountVectorizer.](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) It'll help us to convert a collection of text documents to a matrix of token counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyGOOF_2JOTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Your code here\n",
        "\n",
        "\n",
        "# Define an object of CountVectorizer() as count\n",
        "count = CountVectorizer()\n",
        "\n",
        "# With count object, fit and transfom your twits and save result in a variable name 'bag'\n",
        "# Your code here\n",
        "bag = count.fit_transform(twits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tflJtpKM9Jy",
        "colab_type": "code",
        "outputId": "318490dd-0d42-49a4-ee24-bdc8c4704965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(bag)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 13)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 2)\t1\n",
            "  (1, 7)\t2\n",
            "  (1, 9)\t1\n",
            "  (1, 12)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 15)\t1\n",
            "  (1, 8)\t1\n",
            "  (2, 13)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 1)\t1\n",
            "  (2, 10)\t1\n",
            "  (2, 11)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 6)\t1\n",
            "  (2, 5)\t1\n",
            "  (2, 14)\t1\n",
            "  (2, 4)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZfTKwshJOTj",
        "colab_type": "code",
        "outputId": "839f3537-3a9d-43ae-f8b0-c94bac632b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Find in document of CountVectorizer a function that show us list of feature names\n",
        "# hint: get_feature_names\n",
        "# Your code here\n",
        "count.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['about',\n",
              " 'am',\n",
              " 'amazing',\n",
              " 'best',\n",
              " 'end',\n",
              " 'going',\n",
              " 'how',\n",
              " 'is',\n",
              " 'it',\n",
              " 'ml',\n",
              " 'not',\n",
              " 'sure',\n",
              " 'the',\n",
              " 'this',\n",
              " 'to',\n",
              " 'yes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIHEBjzjJOTr",
        "colab_type": "text"
      },
      "source": [
        "As we can see from executing the preceding command, the vocabulary is stored in a Python array that maps the unique words to integer indices. Next, let's print the feature vectors that we just created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so8IuzHoJOTw",
        "colab_type": "code",
        "outputId": "866a9a82-a333-4d8f-de2e-376b4d367f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Call toarray() on your 'bag' to see the feature vectors\n",
        "# Your code here\n",
        "bag.toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 1],\n",
              "       [1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rglRey6PJOT-",
        "colab_type": "code",
        "outputId": "c230626a-ec15-4a79-d183-be38802ce1f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# What is the index of the word 'is' and how many times it occurs in all three twits?\n",
        "# Hint: You can directly count on feature fectors\n",
        "# Your answer here\n",
        "count.vocabulary_ "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'about': 0,\n",
              " 'am': 1,\n",
              " 'amazing': 2,\n",
              " 'best': 3,\n",
              " 'end': 4,\n",
              " 'going': 5,\n",
              " 'how': 6,\n",
              " 'is': 7,\n",
              " 'it': 8,\n",
              " 'ml': 9,\n",
              " 'not': 10,\n",
              " 'sure': 11,\n",
              " 'the': 12,\n",
              " 'this': 13,\n",
              " 'to': 14,\n",
              " 'yes': 15}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM8EIlOnJOUX",
        "colab_type": "text"
      },
      "source": [
        "Each index position in the feature vectors corresponds to the integer values that are stored as dictionary items in the CountVectorizer vocabulary. For example, the first feature at index position 0 resembles the count of the word 'about' , which only occurs in the last document. These values in the feature vectors are also called the **raw term frequencies**: `tf(t,d )` —the number of times a term `t` occurs in a document `d`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7ErS4TSJOUc",
        "colab_type": "text"
      },
      "source": [
        "### How relevant are words? Term frequency-inverse document frequency\n",
        "\n",
        "We could use these raw term frequencies to score the words in our algorithm. There is a problem though: If a word is very frequent in _all_ documents, then it probably doesn't carry a lot of information. In order to tacke this problem we can use **term frequency-inverse document frequency**, which will reduce the score the more frequent the word is accross all twits. It is calculated like this:\n",
        "\n",
        "\\begin{equation*}\n",
        "tf-idf(t,d) = tf(t,d) ~ idf(t,d)\n",
        "\\end{equation*}\n",
        "\n",
        "_tf(t,d)_ is the raw term frequency descrived above. _idf(t,d)_ is the inverse document frequency, than can be calculated as follows:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\log \\frac{n_d}{1+df\\left(d,t\\right)}\n",
        "\\end{equation*}\n",
        "\n",
        "where `n` is the total number of documents and _df(t,d)_ is the number of documents where the term `t` appears. \n",
        "\n",
        "The `1` addition in the denominator is just to avoid zero term for terms that appear in all documents, will not be entirely ignored. Ans the `log` ensures that low frequency term don't get too much weight.\n",
        "\n",
        "Fortunately for us `scikit-learn` does all those calculations for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKqHf8upJOUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Formatting the number to 2 digits after the decimal point by showing on this notebook\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Feed the tf-idf Vectorizer with twits using fit_transform()\n",
        "tfidf_vec = tfidf.fit_transform(twits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts8FjSRuO27L",
        "colab_type": "code",
        "outputId": "1903846b-5fe7-43d8-f05d-a4e0e0fc5653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "tfidf.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['about',\n",
              " 'am',\n",
              " 'amazing',\n",
              " 'best',\n",
              " 'end',\n",
              " 'going',\n",
              " 'how',\n",
              " 'is',\n",
              " 'it',\n",
              " 'ml',\n",
              " 'not',\n",
              " 'sure',\n",
              " 'the',\n",
              " 'this',\n",
              " 'to',\n",
              " 'yes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWKzDRAKJOUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now what is the weight of the word 'is' and 'amazing'?\n",
        "# hint: using \n",
        "# tfidf.get_feature_names()\n",
        "# tfidf_vec.toarray()\n",
        "# Your answer here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRb9SGS8PjbN",
        "colab_type": "code",
        "outputId": "d62ffdcb-21e6-456c-9810-1ce0d8d272de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "tfidf_vec.toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.72, 0.  , 0.  , 0.  , 0.  , 0.43, 0.  , 0.  , 0.  ,\n",
              "        0.  , 0.  , 0.55, 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.  , 0.4 , 0.  , 0.  , 0.  , 0.47, 0.4 , 0.4 , 0.  ,\n",
              "        0.  , 0.4 , 0.  , 0.  , 0.4 ],\n",
              "       [0.33, 0.33, 0.  , 0.  , 0.33, 0.33, 0.33, 0.2 , 0.  , 0.  , 0.33,\n",
              "        0.33, 0.  , 0.25, 0.33, 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbhB9n7CJOUs",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Data clean up\n",
        "\n",
        "### Removing stop words\n",
        "\n",
        "Now that we know how to format and score our input. Let's look at our **real** vocabulary. Specifically, the most common words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG6gXimwJOUv",
        "colab_type": "code",
        "outputId": "27662645-de4a-4ff7-8027-65f714e59b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Example\n",
        "count = Counter()\n",
        "for word in ['red', 'blue', 'red', 'green', 'blue', 'blue']:\n",
        "    count[word] += 1\n",
        "print(count)\n",
        "print(count.most_common(2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'blue': 3, 'red': 2, 'green': 1})\n",
            "[('blue', 3), ('red', 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEo0YY1_Rl3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twits = [\n",
        "    'This is amazing!',\n",
        "    'ML is the best, yes it is',\n",
        "    'I am not sure about how this is going to end...'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBt_uzyLUBib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_sentiment = ' '.join(sentiment['SentimentText'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h4IOAFcJOU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Counter()\n",
        "\n",
        "# Let's apply the example above to count words in our SentimentText\n",
        "# Your code here\n",
        "for line in sentiment['SentimentText']:\n",
        "  for word in line.split():\n",
        "    vocab[word.lower()] += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYxFZeQvR0_H",
        "colab_type": "code",
        "outputId": "33ea0f80-2957-4ae2-e1d3-f955ebf93aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "vocab.most_common(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 48880),\n",
              " ('the', 29629),\n",
              " ('to', 29177),\n",
              " ('you', 23456),\n",
              " ('a', 21908),\n",
              " ('and', 15826),\n",
              " ('it', 14154),\n",
              " ('my', 13598),\n",
              " ('for', 12378),\n",
              " ('is', 11618)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWsCntp-JOVA",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the most common words are meaningless in terms of sentiment: _I, to, the, and_... they don't give any information on positiveness or negativeness. They're basically **noise** that can most probably be eliminated. These kind of words are called _stop words_, and it is a common practice to remove them when doing text analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYZqaTboJOVC",
        "colab_type": "code",
        "outputId": "69a7ea02-61de-4fe9-8e85-657bbbec9ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwKvARrMJOVI",
        "colab_type": "code",
        "outputId": "99e842a1-598b-4745-ce19-82075289744f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "vocab_reduced = Counter()\n",
        "# Go through all of the items of vocab using vocab.items() and pick only words that are not in 'stop' \n",
        "# and save them in vocab_reduced\n",
        "# Your code here\n",
        "\n",
        "for key, value in vocab.items():\n",
        "  if key not in stop:\n",
        "    vocab_reduced[key] = value\n",
        "\n",
        "vocab_reduced.most_common(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"i'm\", 8167),\n",
              " ('like', 5247),\n",
              " ('get', 5228),\n",
              " ('-', 4922),\n",
              " ('good', 4918),\n",
              " ('u', 4638),\n",
              " ('love', 4146),\n",
              " ('know', 3538),\n",
              " ('lol', 3499),\n",
              " ('go', 3198),\n",
              " ('see', 3036),\n",
              " ('thanks', 2987),\n",
              " ('one', 2972),\n",
              " ('got', 2971),\n",
              " ('im', 2731),\n",
              " ('think', 2692),\n",
              " ('hope', 2564),\n",
              " ('&amp;', 2556),\n",
              " ('going', 2506),\n",
              " ('really', 2446)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH-it8GwJOVQ",
        "colab_type": "text"
      },
      "source": [
        "This looks better, only in the 20 most common words we already see words that make sense: good, love, really... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D29ibvg9JOVU",
        "colab_type": "text"
      },
      "source": [
        "### Removing special characters and \"trash\"\n",
        "\n",
        "If you look closer, you'll see that we're also taking into consideration punctuation signs ('-', ',', etc) and other html tags like `&amp`. We can definitely remove them for the sentiment analysis, but we will try to keep the emoticons, since those _do_ have a sentiment load:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFfNUoImJOVW",
        "colab_type": "code",
        "outputId": "5bf2b6aa-984b-424e-aa70-520de26c35d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def preprocessor(text):\n",
        "    \"\"\" Return a cleaned version of text\n",
        "    \"\"\"\n",
        "    # Remove HTML markup\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    # Save emoticons for later appending\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    # Remove any non-word character and append the emoticons,\n",
        "    # removing the nose character for standarization. Convert to lower case\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Create some random texts for testing the function preprocessor()\n",
        "print(preprocessor(\"sdfjksdhjkf[slksdf]\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sdfjksdhjkf slksdf  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgTdW-UEJOVe",
        "colab_type": "text"
      },
      "source": [
        "We are almost ready! There is another trick we can use to reduce our vocabulary and consolidate words. If you think about it, words like: love, loving, etc. _Could_ express the same positivity. If that was the case, we would be  having two words in our vocabulary when we could have only one: lov. This process of reducing a word to its root is called **stemming**.\n",
        "\n",
        "We also need a _tokenizer_ to break down our twits in individual words. We will implement two tokenizers, a regular one and one that does steaming:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hnFwtR-JOVg",
        "colab_type": "code",
        "outputId": "3673530a-7648-4457-b1ac-29667533c646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "# write a function called `tokenizer()` that split a text into list of words\n",
        "def tokenizer(text):\n",
        "    token = [] \n",
        "    # Your code here\n",
        "    token = text.split()\n",
        "\n",
        "    return token\n",
        "\n",
        "\n",
        "# write a function named `tokenizer_porter()` that split a text into list of words and apply stemming technic\n",
        "# Hint: porter.stem(word)\n",
        "def tokenizer_porter(text):\n",
        "    token = []\n",
        "    # Your code here\n",
        "    token = [porter.stem(word) for word in text.split()]\n",
        "    \n",
        "    return token\n",
        "\n",
        "# Testing\n",
        "print(tokenizer('Hi there, I am loving this, like with a lot of love'))\n",
        "print(tokenizer_porter('Hi there, I am loving this, like with a lot of love'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hi', 'there,', 'I', 'am', 'loving', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n",
            "['Hi', 'there,', 'I', 'am', 'love', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEkQCtvYJOVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the dataset in train and test\n",
        "# Your code here\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = sentiment['SentimentText']\n",
        "y = sentiment['Sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exvQ2ymeJOV0",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS8lFkyrJOV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=stop,\n",
        "                        tokenizer=tokenizer_porter,\n",
        "                        preprocessor=preprocessor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgfEYOJAJOV-",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Classification\n",
        "\n",
        "We are finally ready to train our algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb1sYFeKJOV_",
        "colab_type": "code",
        "outputId": "516f53d7-1f16-43f6-a7d5-5803efd0f570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# A pipeline is what chains several steps together, once the initial exploration is done. \n",
        "# For example, some codes are meant to transform features — normalise numericals, or turn text into vectors, \n",
        "# or fill up missing data, they are transformers; other codes are meant to predict variables by fitting an algorithm,\n",
        "# they are estimators. Pipeline chains all these together which can then be applied to training data\n",
        "clf = Pipeline([('vect', tfidf),\n",
        "                ('clf', LogisticRegression(random_state=0))])\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', 'onc', 'onli', 'ourselv', 'themselv', 'thi', 'veri', 'wa', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=<function preprocessor at 0x7fb5ed867d08>,\n",
              "                                 smooth_idf=True,\n",
              "                                 stop_words=['i', 'me', 'my', 'myself', '...\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenizer_porter at 0x7fb5f34198c8>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='warn', n_jobs=None,\n",
              "                                    penalty='l2', random_state=0, solver='warn',\n",
              "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf9E3-RVzpDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcKBhzeTJOWF",
        "colab_type": "code",
        "outputId": "9d427a53-c16d-4498-92a4-c64a622c611e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "# Now apply those above metrics to evaluate your model\n",
        "# Your code here\n",
        "# Now apply those above metrics to evaluate your model\n",
        "accuracy_score(y_test, y_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7533802704216337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd6YvVcN0A-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVcwq-6Hzw_h",
        "colab_type": "code",
        "outputId": "8e786bc0-e383-4095-e92a-463306811ec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "sns.heatmap(confusion_matrix(y_test, y_predict));"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD8CAYAAAC8TPVwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS6QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjkESReUzz9f",
        "colab_type": "code",
        "outputId": "22b64e62-fe8e-43d4-c83c-207a562db891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "classification_report(y_test, y_predict).split('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['              precision    recall  f1-score   support',\n",
              " '',\n",
              " '           0       0.75      0.66      0.70     10940',\n",
              " '           1       0.76      0.82      0.79     14058',\n",
              " '',\n",
              " '    accuracy                           0.75     24998',\n",
              " '   macro avg       0.75      0.74      0.75     24998',\n",
              " 'weighted avg       0.75      0.75      0.75     24998',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4KPDCihJOWR",
        "colab_type": "text"
      },
      "source": [
        "Finally, let's run some tests :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sVTaRB7JOWU",
        "colab_type": "code",
        "outputId": "3508b568-c251-4d03-ab9c-235ff14c87bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "twits = [\n",
        "    \"This is really bad\",\n",
        "    \"I love this!\",\n",
        "    \":)\",\n",
        "]\n",
        "\n",
        "preds = clf.predict_proba(twits)\n",
        "\n",
        "for i in range(len(twits)):\n",
        "    print(f'{twits[i]} --> Positive, Negative = {preds[i]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is really bad --> Positive, Negative = [0.96 0.04]\n",
            "I love this! --> Positive, Negative = [0.08 0.92]\n",
            ":) --> Positive, Negative = [0.39 0.61]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3NeiZ7iJOWj",
        "colab_type": "text"
      },
      "source": [
        "If we would like to use the classifier in another place, or just not train it again and again everytime, we can save the model in a pickle file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2Ev6SRxJOWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "pickle.dump(clf, open(os.path.join('logisticRegression.pkl'), 'wb'), protocol=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXhJr9DpJOWw",
        "colab_type": "text"
      },
      "source": [
        "## And you're done! I hope you liked this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHOjXn5nJOW2",
        "colab_type": "text"
      },
      "source": [
        "## 2. Bonus: Confusion Matrices\n",
        "\n",
        "https://towardsdatascience.com/taking-the-confusion-out-of-confusion-matrices-c1ce054b3d3e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfXzhJVgJOW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy, pandas\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYTiRK-aJOXA",
        "colab_type": "text"
      },
      "source": [
        "* We use 2 models to predict if a woman is pregnant or not and save the result in \"pregnant.csv\" files.\n",
        "* pregnent dataset has 3 columns:\n",
        "    * Actual is actual result (ground truth)\n",
        "    * model_1_predict, model_2_predict are prediction results from model 1 and model 2\n",
        "\n",
        "**Now, we have to answer the question which model is better?**\n",
        "\n",
        "First of all, let's load dataset and print it out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKS4ZRfgJOXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pregnant = pd.read_csv('pregnant.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcTJDLpD1C6g",
        "colab_type": "code",
        "outputId": "9f8585df-1c19-4e4b-d479-7d174d662ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_pregnant.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>model_1_predict</th>\n",
              "      <th>model_2_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Actual  model_1_predict  model_2_predict\n",
              "0       0                0                0\n",
              "1       1                0                1\n",
              "2       0                0                0\n",
              "3       0                0                0\n",
              "4       0                0                0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc9xgpmqJOXP",
        "colab_type": "text"
      },
      "source": [
        "### Calculate True Positive, False Positive, True Negative, False Negative of model 1\n",
        "![Alt](https://cdn-images-1.medium.com/max/800/1*g5zpskPaxO8uSl0OWT4NTQ.png)\n",
        "Note\n",
        "* Positive : 1(Pregnant)\n",
        "* Negative : 0(Not Pregnant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emwlZKOnJOXV",
        "colab_type": "text"
      },
      "source": [
        "True Positive : Predict **Positive** and it's **True**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqtopSBsJOXb",
        "colab_type": "code",
        "outputId": "1641913e-cb94-4d36-f3df-3e709e6034d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Predict Positive\n",
        "positive = df_pregnant['model_1_predict'] == 1\n",
        "# It's True (correct prediction)\n",
        "correct_predict = df_pregnant['Actual'] == 1\n",
        "\n",
        "TP = sum(positive & correct_predict)\n",
        "TP"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZrCRZ9bJOXi",
        "colab_type": "text"
      },
      "source": [
        "False Positive: Predict **Positive** and it's **False**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF7gDZg7JOXs",
        "colab_type": "code",
        "outputId": "58c01ac5-61dc-4b7d-ee66-e7b2edafe953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Predict Positive\n",
        "positive = df_pregnant['model_1_predict'] == 1\n",
        "# It's False (incorrect prediction)\n",
        "incorrect_predict = df_pregnant['Actual'] == 0\n",
        "\n",
        "FP = sum(positive & incorrect_predict)\n",
        "FP"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGX3mGhGJOXx",
        "colab_type": "text"
      },
      "source": [
        "True Negative : Predict **Negative** and it's **True**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScdnuYAJJOXz",
        "colab_type": "code",
        "outputId": "d29cef07-4ce7-42e4-d8e1-8151847f1202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Predict Negative\n",
        "negative = df_pregnant['model_1_predict'] == 0\n",
        "# It's True (correct prediction)\n",
        "correct_predict = df_pregnant['Actual'] == 0\n",
        "\n",
        "TN = sum(negative & correct_predict)\n",
        "TN"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "385"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSmlvgjIJOX4",
        "colab_type": "text"
      },
      "source": [
        "False Negative: Predict **Negative** and it's **False**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_ZuwjRHJOX5",
        "colab_type": "code",
        "outputId": "7dcdb05e-cd5c-4738-82fd-ca5092f1e217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Predict Negative\n",
        "negative = df_pregnant['model_1_predict'] == 0\n",
        "# It's False (incorrect prediction)\n",
        "incorrect_predict = df_pregnant['Actual'] == 1\n",
        "\n",
        "FN = sum(negative & incorrect_predict)\n",
        "FN"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkOtpK57JOX-",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy vs Precision vs Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoXc7UNWJOX_",
        "colab_type": "text"
      },
      "source": [
        "![Alt img](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/440px-Precisionrecall.svg.png)\n",
        "\n",
        "- Accuracy (all correct / all) = (TP + TN) / (TP + TN + FP + FN)\n",
        "- Precision (true positives / predicted positives) = TP / (TP + FP)\n",
        "- Sensitivity aka Recall (true positives / all actual positives) = TP / (TP + FN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHQdgZY4JOYC",
        "colab_type": "code",
        "outputId": "5c4b0a2c-fe22-4f80-f926-eb9a84c0c468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "Precision = TP / (TP + FP)\n",
        "Recall = TP / (TP + FN)\n",
        "print(\"Accuracy : \", Accuracy)\n",
        "print(\"Precision: \", Precision)\n",
        "print(\"RecalL   : \", Recall)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.85\n",
            "Precision:  0.38095238095238093\n",
            "RecalL   :  0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FgC1j5wJOYR",
        "colab_type": "text"
      },
      "source": [
        "### Thank to Sklearn for making our life more easier with classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtrFQaQZJOYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDoD6xpuJOYp",
        "colab_type": "code",
        "outputId": "df3a0dfd-1aee-4457-c0af-aa7860b83580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "confusion = confusion_matrix(df_pregnant['Actual'], df_pregnant['model_1_predict'])\n",
        "report = classification_report(df_pregnant['Actual'], df_pregnant['model_1_predict'])\n",
        "print(confusion)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[385  65]\n",
            " [ 10  40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.86      0.91       450\n",
            "           1       0.38      0.80      0.52        50\n",
            "\n",
            "    accuracy                           0.85       500\n",
            "   macro avg       0.68      0.83      0.71       500\n",
            "weighted avg       0.92      0.85      0.87       500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "48lEajsOJOYt",
        "colab_type": "code",
        "outputId": "9a207b64-d9c5-4aa5-ff0d-ee4de42edc14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# apply the same with model 2\n",
        "confusion = confusion_matrix(df_pregnant['Actual'], df_pregnant['model_2_predict'])\n",
        "report = classification_report(df_pregnant['Actual'], df_pregnant['model_2_predict'])\n",
        "print(confusion)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[395  55]\n",
            " [  5  45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.88      0.93       450\n",
            "           1       0.45      0.90      0.60        50\n",
            "\n",
            "    accuracy                           0.88       500\n",
            "   macro avg       0.72      0.89      0.76       500\n",
            "weighted avg       0.93      0.88      0.90       500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVpw01804v57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}